{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from stlcgpp.formula import *\n",
    "from stlcgpp.tests import *\n",
    "from stlcgpp.viz import *\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "rc('text', usetex=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE\n",
    "If using Expressions to define formulas, `stlcgpp` expects input signals to be of size `[time_dim]`.\n",
    "If using Predicates to define formulas, `stlcgpp` expects input signals to be of size `[time_dim, state_dim]` where `state_dim` is the expected input size of your predicate function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance_to_origin(states):\n",
    "    return torch.norm(states[...,:2], dim=-1, keepdim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.4142, 1.4142, 1.4142, 1.4142, 1.4142, 1.4142, 1.4142, 1.4142, 1.4142,\n",
       "        1.4142])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = 10\n",
    "compute_distance_to_origin(torch.ones([T, 2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Expressions\n",
    "Expressions are placeholders for input signals. Specifically, it is assuming the signal is already a 1D array, such as the output of a predicate function. \n",
    "\n",
    "This is useful if you have signals from predicates computed already. \n",
    "\n",
    "In general, this is useful for readability and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Input Expression does not have numerical values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m distance_to_origin_exp \u001b[38;5;241m=\u001b[39m Expression(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmagnitude\u001b[39m\u001b[38;5;124m\"\u001b[39m, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;66;03m# can define an Expression without setting values for the expression right now\u001b[39;00m\n\u001b[1;32m      2\u001b[0m formula_exp \u001b[38;5;241m=\u001b[39m Eventually(distance_to_origin_exp \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.5\u001b[39m) \u001b[38;5;66;03m# can define an STL formula given an expression, again, the value of the expression does not need to be set yet\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mformula_exp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdistance_to_origin_exp\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# <---- this will throw an error since the expression does not have values set yet\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/stlcg-plus-plus/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repos/stlcg-plus-plus/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/repos/stlcg-plus-plus/stlcgpp/formula.py:259\u001b[0m, in \u001b[0;36mSTLFormula.forward\u001b[0;34m(self, signal, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, signal: torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    253\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"    \u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;124;03m    Evaluates the robustness_trace given the input. The input is converted to the numerical value first.\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \n\u001b[1;32m    256\u001b[0m \u001b[38;5;124;03m    See  STLFormula.robustness_trace\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 259\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_input_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrobustness_trace(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/repos/stlcg-plus-plus/stlcgpp/formula.py:179\u001b[0m, in \u001b[0;36mconvert_to_input_values\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, Expression):\n\u001b[0;32m--> 179\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput Expression does not have numerical values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;66;03m# if Expression is not time reversed\u001b[39;00m\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mvalue\n",
      "\u001b[0;31mAssertionError\u001b[0m: Input Expression does not have numerical values"
     ]
    }
   ],
   "source": [
    "distance_to_origin_exp = Expression(\"magnitude\", value=None) # can define an Expression without setting values for the expression right now\n",
    "formula_exp = Eventually(distance_to_origin_exp < 0.5) # can define an STL formula given an expression, again, the value of the expression does not need to be set yet\n",
    "\n",
    "\n",
    "formula_exp(distance_to_origin_exp) # <---- this will throw an error since the expression does not have values set yet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so let's go ahead and set a value for the expression\n",
    "T = 5\n",
    "states = torch.randn([T, 2])\n",
    "states_norm = compute_distance_to_origin(states)   # compute distance to origin\n",
    "\n",
    "distance_to_origin_exp.set_value(states_norm)   # set value for Expression\n",
    "\n",
    "# compute robustness trace\n",
    "formula_exp(distance_to_origin_exp) # <---- this will no longer throw an error since the expression has a value set\n",
    "\n",
    "# alternatively, we can directly plug any torch.tensor and evaluate the robustness without \n",
    "states2 = torch.randn([T, 2])\n",
    "states_norm2 = compute_distance_to_origin(states2)   # compute distance to origin\n",
    "formula_exp(states_norm2) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the robustness value (instead of trace) and take the derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustness = formula_exp.robustness(states_norm) \n",
    "print(f\"Robustness value: {robustness:.3f}\\n\")\n",
    "\n",
    "gradient = torch.func.grad(formula_exp.robustness)(states_norm) \n",
    "print(f\"Gradient of robustness value w.r.t. input:\\n {gradient}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply a smooth max/min approximation by selecting a `approx_method` and `temperature`.\n",
    "The default `approx_method` is `true`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approx_method = \"logsumexp\"  # or \"softmax\"\n",
    "temperature = 1. # needs to be > 0\n",
    "\n",
    "robustness = formula_exp.robustness(states_norm, approx_method=approx_method, temperature=temperature) \n",
    "print(f\"Robustness value: {robustness:.3f}\\n\")\n",
    "\n",
    "gradient = torch.func.grad(formula_exp.robustness)(states_norm, approx_method=approx_method, temperature=temperature) \n",
    "print(f\"Gradient of robustness value w.r.t. input:\\n {gradient}\") # <----- gradients are spread across different values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For formulas that are defined with two different Expressions, we need to be careful about the signals we are feeding in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if both subformulas use the same signal, then we can do this\n",
    "phi = (distance_to_origin_exp > 0) & (distance_to_origin_exp < 0.5)  \n",
    "phi(states_norm)\n",
    "\n",
    "\n",
    "# if the formula depends on two different signals, then we need to provide the two signals as tuple\n",
    "distance_to_origin_exp = Expression(\"magnitude\", value=None)\n",
    "speed_exp = Expression(\"speed\", value=None)\n",
    "\n",
    "phi = (distance_to_origin_exp > 0) & (speed_exp < 0.5)  \n",
    "\n",
    "phi(states_norm) # <--- Will give WRONG ANSWER\n",
    "\n",
    "\n",
    "speed = torch.randn([T])\n",
    "input_correct_order = (states_norm, speed)\n",
    "input_wrong_order = (speed, states_norm)\n",
    "phi(input_correct_order) # <--- Will give desired answer\n",
    "phi(input_wrong_order) # <--- Will give WRONG ANSWER since the ordering of the input does not correspond to how phi is defined\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Predicates\n",
    "Predicates are the functions that an N-D signal is passed through and its outputs are then passed through each operation of the STL formula.\n",
    "We can construct an STL formula by specifying the predicate functions and the connectives and temporal operations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_to_origin_pred = Predicate(\"magnitude\", predicate_function=compute_distance_to_origin) # define a predicate function with a name and the function\n",
    "formula_pred = Eventually(distance_to_origin_pred < 0.5) # define the STL formula\n",
    "\n",
    "# so let's go ahead and set a value for the input N-D array which will be the input into the predicate function.\n",
    "T = 5\n",
    "states = torch.randn([T, 2])  # 2D signal\n",
    "output_from_using_predicate = formula_pred(states) # compute distance to origin INSIDE \n",
    "\n",
    "\n",
    "# NOTE: this is equivalent to the following with expressions\n",
    "states_norm = compute_distance_to_origin(states)   # computes distance to origin OUTSIDE \n",
    "output_from_using_expression = formula_exp(states_norm) \n",
    "\n",
    "\n",
    "# check if we get the same answer\n",
    "torch.isclose(output_from_using_predicate, output_from_using_expression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can compute the robustness value (instead of trace) and take the derivative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approx_method = \"logsumexp\"  # or \"softmax\"\n",
    "temperature = 1. # needs to be > 0\n",
    "\n",
    "robustness = formula_pred.robustness(states, approx_method=approx_method, temperature=temperature) \n",
    "print(f\"Robustness value: {robustness:.3f}\\n\")\n",
    "\n",
    "gradient = torch.func.grad(formula_pred.robustness)(states, approx_method=approx_method, temperature=temperature) \n",
    "print(f\"Gradient of robustness value w.r.t. input:\\n {gradient}\") # <----- gradients are spread across different values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that when taken gradients with formulas defined with predicates, the input is the N-D signal which is passed into the predicate function and other robustness formulas. That is to say, the gradient will be influenced by the choice of the predicate. \n",
    "\n",
    "To get the same gradient output when using Expressions, we need to do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(states):\n",
    "    states_norm = compute_distance_to_origin(states)   # compute distance to origin\n",
    "    return formula_exp.robustness(states_norm, approx_method=approx_method, temperature=temperature) \n",
    "\n",
    "torch.func.grad(foo)(states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the masking and recurrent approach to computing SRL robustness\n",
    "The main difference between `STLCG` and `STLCG++` is that `STLCG` relies on recurrent computations to compute robustness and `STLCG++` used a masking approach. More details are provided in the accompanying paper.\n",
    "\n",
    "Next, we show some examples on how call the recurrent implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicate = Predicate(\"identity\", lambda x: x)\n",
    "recurrent = AlwaysRecurrent(predicate > 0.)\n",
    "mask = Always(predicate > 0.)\n",
    "\n",
    "# recurrent = UntilRecurrent(predicate > 0., predicate < 5.)\n",
    "# mask = Until(predicate > 0., predicate < 5.)\n",
    "\n",
    "T = 10\n",
    "signal =  torch.arange(T).float()\n",
    "signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# robustness trace using the masking approach.\n",
    "# the values are exactly what we expect.\n",
    "mask(signal), mask.robustness(signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the robustness trace using the recurrent method, we need to input the signal **backward** in time\n",
    "\n",
    "(In the future, will handling the reversing of signal internally, and user does not need to deal with it.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_flip = signal.flip(0)\n",
    "recurrent(signal_flip).flip(0), recurrent.robustness(signal_flip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can visualize the STL formulas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_stl_graph(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_stl_graph(recurrent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
